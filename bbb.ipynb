{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64640f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "@@@@@@ 0.012354564807575606\n",
      "4001 1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Training loss: 0.595356,Training loss2: 0.597825, VAL loss: 0.545570, VAL loss2: 0.480220\n",
      "Epoch:1, Training loss: 0.505196,Training loss2: 0.448843, VAL loss: 0.564370, VAL loss2: 0.505945\n",
      "Epoch:2, Training loss: 0.468822,Training loss2: 0.391199, VAL loss: 0.489678, VAL loss2: 0.417228\n",
      "Epoch:3, Training loss: 0.425071,Training loss2: 0.329100, VAL loss: 0.579949, VAL loss2: 0.555060\n",
      "Epoch:4, Training loss: 0.401862,Training loss2: 0.298953, VAL loss: 0.539585, VAL loss2: 0.496445\n",
      "Epoch:5, Training loss: 0.365318,Training loss2: 0.249494, VAL loss: 0.495902, VAL loss2: 0.418437\n",
      "Epoch:6, Training loss: 0.341829,Training loss2: 0.223054, VAL loss: 0.663135, VAL loss2: 0.737944\n",
      "Epoch:7, Training loss: 0.321282,Training loss2: 0.201413, VAL loss: 0.555770, VAL loss2: 0.530450\n",
      "Epoch:8, Training loss: 0.297531,Training loss2: 0.175692, VAL loss: 0.533468, VAL loss2: 0.496278\n",
      "Epoch:9, Training loss: 0.279643,Training loss2: 0.155861, VAL loss: 0.503480, VAL loss2: 0.404581\n",
      "Epoch:10, Training loss: 0.262973,Training loss2: 0.137375, VAL loss: 0.488171, VAL loss2: 0.377232\n",
      "Epoch:11, Training loss: 0.247866,Training loss2: 0.129309, VAL loss: 0.487928, VAL loss2: 0.384056\n",
      "Epoch:12, Training loss: 0.232365,Training loss2: 0.109365, VAL loss: 0.501365, VAL loss2: 0.392307\n",
      "Epoch:13, Training loss: 0.222816,Training loss2: 0.101356, VAL loss: 0.500520, VAL loss2: 0.421153\n",
      "Epoch:14, Training loss: 0.213167,Training loss2: 0.095396, VAL loss: 0.532586, VAL loss2: 0.430341\n",
      "Epoch:15, Training loss: 0.200498,Training loss2: 0.085072, VAL loss: 0.506366, VAL loss2: 0.406603\n",
      "Epoch:16, Training loss: 0.188122,Training loss2: 0.076519, VAL loss: 0.534240, VAL loss2: 0.431926\n",
      "Epoch:17, Training loss: 0.178422,Training loss2: 0.070580, VAL loss: 0.510114, VAL loss2: 0.409966\n",
      "Epoch:18, Training loss: 0.169460,Training loss2: 0.065049, VAL loss: 0.502902, VAL loss2: 0.413390\n",
      "Epoch:19, Training loss: 0.165102,Training loss2: 0.063148, VAL loss: 0.502906, VAL loss2: 0.399655\n",
      "Epoch:20, Training loss: 0.159610,Training loss2: 0.059657, VAL loss: 0.517241, VAL loss2: 0.416927\n",
      "Epoch:21, Training loss: 0.152723,Training loss2: 0.057313, VAL loss: 0.512497, VAL loss2: 0.405891\n",
      "Epoch:22, Training loss: 0.146133,Training loss2: 0.053839, VAL loss: 0.514035, VAL loss2: 0.408178\n",
      "Epoch:23, Training loss: 0.140334,Training loss2: 0.051405, VAL loss: 0.519319, VAL loss2: 0.414280\n",
      "Epoch:24, Training loss: 0.141384,Training loss2: 0.052541, VAL loss: 0.510440, VAL loss2: 0.407543\n",
      "Epoch:25, Training loss: 0.139011,Training loss2: 0.051782, VAL loss: 0.521740, VAL loss2: 0.420725\n",
      "Epoch:26, Training loss: 0.137091,Training loss2: 0.051628, VAL loss: 0.518075, VAL loss2: 0.415485\n",
      "Epoch:27, Training loss: 0.134747,Training loss2: 0.051382, VAL loss: 0.522331, VAL loss2: 0.422432\n",
      "Epoch:28, Training loss: 0.136612,Training loss2: 0.052970, VAL loss: 0.525493, VAL loss2: 0.424565\n",
      "Epoch:29, Training loss: 0.135439,Training loss2: 0.053092, VAL loss: 0.521871, VAL loss2: 0.422465\n",
      "Epoch:30, Training loss: 0.135975,Training loss2: 0.054115, VAL loss: 0.526451, VAL loss2: 0.429121\n",
      "Epoch:31, Training loss: 0.136802,Training loss2: 0.054948, VAL loss: 0.533219, VAL loss2: 0.436482\n",
      "Early stopped at: 31\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "/home/juy024/bbb/results_country.csv\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "/home/juy024/bbb/results.csv\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt;\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def load_data():\n",
    "    trainloader = CNNDataloader()\n",
    "    train_loader=[]\n",
    "    val_loader=[]\n",
    "    for i, (data_in, y) in enumerate(trainloader):\n",
    "        if i <= 4000:\n",
    "            train_loader.append([data_in, y])\n",
    "        if i > 4000:\n",
    "            val_loader.append([data_in, y])\n",
    "\n",
    "    print(len(train_loader),  len(val_loader))\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def z_score(p):\n",
    "    return (p-np.mean(p))/np.std(p)\n",
    "\n",
    "def get_model():\n",
    "    model = CNN()\n",
    "    return model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.Conv=nn.ModuleList( [nn.Conv2d(1,519,(1, 224))] )\n",
    "        #self.Conv=nn.ModuleList( [nn.Conv2d(1,519,(n, 224)) for n in (2, 3, 4)] )\n",
    "\n",
    "        self.fc=nn.Linear(519*1, 2)\n",
    "\n",
    "    def relu_pool(self, In, conv):\n",
    "        In=F.relu(conv(In)).squeeze(3)\n",
    "        In=F.max_pool1d(In, In.size(2)).squeeze(2)\n",
    "        return In\n",
    "\n",
    "    def forward(self, out):\n",
    "        out=out.unsqueeze(0)\n",
    "        out=out.unsqueeze(1)\n",
    "        out=torch.cat([self.relu_pool(out,conv) for conv in self.Conv],1)\n",
    "        out=self.fc(out)\n",
    "        return out\n",
    "\n",
    "class CNNDataloader():\n",
    "    def __init__(self):\n",
    "        X = []\n",
    "        Y = []\n",
    "        avg=0\n",
    "        avg_num=0\n",
    "        i=0\n",
    "        for index,row in df.iterrows():\n",
    "        #for i in range(len(df)):\n",
    "        #for i in range(1200):\n",
    "            i=i+1\n",
    "            if i <= 5200:\n",
    "                img=np.load(image_dir+row['filename'])['x']\n",
    "                X.append(img[0])\n",
    "                if row['urban']:\n",
    "                    Y.append([row['wealthpooled'], 1])\n",
    "                else:\n",
    "                    Y.append([row['wealthpooled'], 0])\n",
    "\n",
    "                #X.append(np.rot90(img[0]))\n",
    "                #if row['urban']:\n",
    "                #    Y.append([row['wealthpooled'], 1])\n",
    "                #else:\n",
    "                #    Y.append([row['wealthpooled'], 0])\n",
    "\n",
    "                avg=avg+row['wealthpooled']\n",
    "                avg_num=avg_num+1\n",
    "                if int(i/100) == i/100:\n",
    "                    print(i)\n",
    "\n",
    "        self.x_train=X\n",
    "        self.y_train=Y\n",
    "        avg=avg/avg_num\n",
    "        print('@@@@@@',avg)\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx], self.y_train[idx]\n",
    "\n",
    "class Train():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.__train_loader, self.__val_loader = load_data()\n",
    "\n",
    "        self.__epochs = 200\n",
    "        self.lr = 0.001\n",
    "        self.__current_epoch = 0\n",
    "        self.__patience = 20\n",
    "        self.__early_stop = True\n",
    "        self.__lowest_val_loss = 10000\n",
    "        self.__training_losses = []\n",
    "        self.__training_losses2 = []\n",
    "        self.__val_losses = []\n",
    "        self.__val_losses2 = []\n",
    "        self.__model = get_model()\n",
    "        self.__model.to(device)\n",
    "        self.__criterion2 = torch.nn.MSELoss()\n",
    "        self.__criterion = torch.nn.L1Loss(reduction='mean')\n",
    "\n",
    "        #self.__optimizer = torch.optim.Adam(self.__model.parameters(), lr=self.lr)\n",
    "        self.__optimizer = torch.optim.SGD(self.__model.parameters(), lr=self.lr, momentum=0.5, weight_decay=0.002)\n",
    "        self.__scheduler = torch.optim.lr_scheduler.ExponentialLR(self.__optimizer, gamma=0.9)\n",
    "\n",
    "\n",
    "        self.__init_model()\n",
    "\n",
    "    def __init_model(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.__model = self.__model.cuda().float()\n",
    "            self.__criterion = self.__criterion.cuda()\n",
    "\n",
    "    def run(self):\n",
    "        start_epoch = self.__current_epoch\n",
    "        count = 0\n",
    "        best_model=\"\"\n",
    "        for epoch in range(start_epoch, self.__epochs):\n",
    "            start_time = datetime.now()\n",
    "            self.__current_epoch = epoch\n",
    "            train_loss, train_loss2 = self.__train()\n",
    "            val_loss, val_loss2 = self.__val()\n",
    "            self.__training_losses.append(train_loss)\n",
    "            self.__training_losses2.append(train_loss2)\n",
    "            self.__val_losses.append(val_loss)\n",
    "            self.__val_losses2.append(val_loss2)\n",
    "            print(\"Epoch:{}, Training loss: {:.6f},Training loss2: {:.6f}, VAL loss: {:.6f}, VAL loss2: {:.6f}\".format(epoch, train_loss, train_loss2, val_loss, val_loss2))\n",
    "\n",
    "            self.__scheduler.step()\n",
    "\n",
    "            if val_loss >= self.__lowest_val_loss:\n",
    "                count+=1\n",
    "            else:\n",
    "                count=0\n",
    "                self.__lowest_val_loss = val_loss\n",
    "                best_model=copy.deepcopy(self.__model)\n",
    "\n",
    "            if self.__early_stop and count == self.__patience:\n",
    "                print(\"Early stopped at: {}\".format(epoch))\n",
    "                break\n",
    "\n",
    "        return best_model\n",
    "\n",
    "    def __train(self):\n",
    "        self.__model.train()\n",
    "        training_loss = 0\n",
    "        training_loss2 = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for i, (data_in, y) in enumerate(self.__train_loader):\n",
    "            data_in = z_score(data_in)\n",
    "            data_in = torch.tensor(data_in, dtype=torch.float32).to(device)\n",
    "            y=torch.tensor(y, dtype=torch.float32).to(device)\n",
    "            y=y.unsqueeze(0)\n",
    "            self.__optimizer.zero_grad()\n",
    "\n",
    "            out = self.__model(data_in)\n",
    "            #out=out[0].unsqueeze(0)\n",
    "\n",
    "            loss = self.__criterion(out, y)\n",
    "            loss2 = self.__criterion2(out, y)\n",
    "            loss.backward()\n",
    "\n",
    "            training_loss += loss.item()\n",
    "            training_loss2 += loss2.item()\n",
    "            self.__optimizer.step()\n",
    "\n",
    "        training_loss = training_loss / len(self.__train_loader)\n",
    "        training_loss2 = training_loss2 / len(self.__train_loader)\n",
    "        return training_loss, training_loss2\n",
    "\n",
    "    def __val(self):\n",
    "        self.__model.eval()\n",
    "        val_loss = 0\n",
    "        val_loss2 = 0\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            for i, (data_in, y) in enumerate(self.__val_loader):\n",
    "                data_in = z_score(data_in)\n",
    "                data_in = torch.tensor(data_in, dtype=torch.float32).to(device)\n",
    "                y=torch.tensor(y, dtype=torch.float32).to(device)\n",
    "                y=y.unsqueeze(0)\n",
    "\n",
    "                out = self.__model(data_in)\n",
    "                #out=out[0].unsqueeze(0)\n",
    "                \n",
    "                loss = self.__criterion(out, y)\n",
    "                loss2 = self.__criterion2(out, y)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_loss2 += loss2.item()\n",
    "            val_loss = val_loss / len(self.__val_loader)\n",
    "            val_loss2 = val_loss2 / len(self.__val_loader)\n",
    "        return val_loss, val_loss2\n",
    "\n",
    "if __name__=='__main__':\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    import os\n",
    "    path = os.getcwd()\n",
    "    _uname = path.split('/')[2]\n",
    "    poverty_dir=f'/home/{_uname}/public/cs255-sp22-a00-public/poverty'\n",
    "    image_dir=poverty_dir+'/anon_images/'\n",
    "    train_table=f'/home/{_uname}/public/Datasets_public/Final_Project_Data/train.csv'\n",
    "    df=pd.read_csv(train_table,index_col=0)\n",
    "    df.index=df['filename']\n",
    "    #print(image_dir+df.filename[9])\n",
    "    #img=np.load(image_dir+df.filename[9])['x']\n",
    "    #print(img.shape)\n",
    "    #plt.imshow(img[0].squeeze())\n",
    "    #print(df.wealthpooled[9],df.urban[9])\n",
    "    best_model=Train().run()\n",
    "    folds=[{'in':'country_test_reduct.csv','out':'results_country.csv'},\n",
    "            {'in':'random_test_reduct.csv','out':'results.csv'}]\n",
    "\n",
    "    for fold_i in range(len(folds)):\n",
    "        fold=folds[fold_i]\n",
    "\n",
    "        test_csv=f'/home/{_uname}/public/Datasets_public/Final_Project_Data/{fold[\"in\"]}'\n",
    "        test=pd.read_csv(test_csv,index_col=0)\n",
    "        #test.index=test['filename']\n",
    "        #print (test)\n",
    "\n",
    "        out_df=pd.DataFrame()\n",
    "        out_df['filename'] = test['filename']\n",
    "        out_df['urban']=test['urban']\n",
    "        out_df['pred_wo_abstention']=0\n",
    "        out_df['pred_with_abstention']=0\n",
    "        #out_df.set_index('filename', inplace=True)\n",
    "        #print (out_df)\n",
    "\n",
    "        avg=0\n",
    "        for i in range(len(out_df)):\n",
    "            filename=out_df.iloc[i,0]\n",
    "            img=np.load(image_dir+filename)['x']\n",
    "            test_data = z_score(img[0])\n",
    "            test_data=torch.tensor(test_data, dtype=torch.float32).to(device)\n",
    "            out = best_model(test_data)\n",
    "            #print(out)\n",
    "            #print(image_dir+filename)\n",
    "            if out[0][1] < 0.5:\n",
    "                out_df.iloc[i,1]='False'\n",
    "            else:\n",
    "                out_df.iloc[i,1]='True'\n",
    "            if out[0][0] < avg:\n",
    "                out_df.iloc[i,2]=-1\n",
    "                if out[0][0] < avg-0.4:\n",
    "                    out_df.iloc[i,3]=-1\n",
    "                else:\n",
    "                    out_df.iloc[i,3]=0\n",
    "            else:\n",
    "                if out[0][0] > avg+0.4:\n",
    "                    out_df.iloc[i,3]=-1\n",
    "                else:\n",
    "                    out_df.iloc[i,3]=0\n",
    "                out_df.iloc[i,2]=1\n",
    "                out_df.iloc[i,3]=1\n",
    "\n",
    "            #print(out_df.iloc[i,0],out_df.iloc[i,1],out_df.iloc[i,2],out_df.iloc[i,3])\n",
    "            \n",
    "        out_df=out_df.reset_index(drop=True)\n",
    "        outFile=f'/home/{_uname}/bbb/{fold[\"out\"]}'\n",
    "        out_df.to_csv(outFile)\n",
    "        print('\\n\\n'+'-'*60)\n",
    "        print(outFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02232c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e6e5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52720cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407beffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c978a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
